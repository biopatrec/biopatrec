#summary Principal Component Analysis

NOTE: This is an ongoing development and therefore the documentation is not yet ready.

= Introduction =
 Principal Component Analysis (PCA) is one of the widely used Dimensionality Reduction Technique. In Pattern Recognition, Dimensionality Reduction can be categorized as Feature selection or Feature Projection. PCA is an unsupervised Feature reduction or Feature projection technique which does not require any information about class labels. The central idea of PCA is to reduce the dimensionality of large data set in to low dimensional space while preserving as much as possible variation present in the data.

 PCA is a linear transformation also called as karhunenloeve tranform (KLT). It transforms number of correlated variables into small number    of uncorrelated variables called as Principal Components (PC's).The first PC accounts much of variability in the data and the succeeding components accounts remaining variability. It is a true eigen vector based multivariate analysis reveling internal structure of the data which is best explains the variance in the data. 


= Algorithm =
PCA Algorithm is summarized as follows
  
   
   * *Step-1*: Compute the Normalization

   * *Step-2*: Compute sample Covariance matrix.

   * *Step-3*: Compute Eigen vectors and Eigen values. 

   * *Step-4*: Sort Eigen values in descending order.

   * *Step-7*: Arrange the Eigen vectors with their corresponding  eigen values in descending order.
 
   * *Step-8*: Choose first k largest eigen vectors. 

   * *Step-9*: Project the data on to k eigen vectors.

=== How to Chose k ===
   To choose k following criterion is used.
   Consider Eigenvalue is Lamda.
  ∑ ^𝛌^i / ∑^𝛌^j > Thershold(eg.0.9999) where i = 1,2,....k and j = 1,2,....N
                  
  
== Implementation == 
  The implementation of PCA in PatRec is as follows

 PCA requires normalization for the data. Data is normalized according to the [PatRec] normalizations method.

 *1. Compute PCA on Training Set and save Eigen Vector of Training Set in PatRec.

 *2. For Validation and Testing Sets, Project the Eigen vectors of  Trainig Set on to the Testing and Validation.

 *3. Training and Validation sets both are used in Offline training and Testing set is used in [Accuracy_PatRec].

= Adding PCA in [BioPatRec]=
 * PatRec GUI
  * Popup Menu is created and Called it as 'pm_FeatureReduction'.
  * pm_FeatureReduction callback function is modified such that, If 'PCA' has selected in Popup Menu then, instead of considering top 4, top 3 or top 2 Features, It automatically selects all Features.

* [OfflinePatRec]
   
 * A new variable called 'FeatureReduction' struct is saved in PatRec which contains Eigen vectors and algorithm named as 'PCA'



= Function roadmap =
  
 * *Training* 
  * PCAFeatureReduction 
  * FeatureReduction
    * Input  : trSets, vSets
    * Output : trSets, vSets
  
  * *Testing*
    * ApplyFeatureRedction
      * Input : x (Accuracy_PatRec)
      * Output: x
    * PCATest
    
     
  